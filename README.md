# Training a PyTorch Text Summarization Model on [Vertex AI](https://cloud.google.com/vertex-ai) using a pretrained Huggingface model

## Fine-tuning pre-trained [mT5](https://huggingface.co/google/mt5-small) and [mBART](https://huggingface.co/mrm8488/mbart-large-finetuned-opus-en-es-translation) model for a text summarization task in spanish 

** In progress**

## The dataset

We will be using [MLSUM Dataset](https://https://huggingface.co/datasets/mlsum) from [Hugging Face Datasets](https://huggingface.co/datasets).

MLSUM is the first large-scale MultiLingual SUMmarization dataset. Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -- namely, French, German, Spanish, Russian, Turkish. Together with English newspapers from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community. We report cross-lingual comparative analyses based on state-of-the-art systems. These highlight existing biases which motivate the use of a multi-lingual dataset

## Problem description
** In progress**

## Content
** In progress**

## Contributing
If you find some bug or typo, please let me know or fixit and push it to be analyzed. 

## License

These notebooks are under a public GNU License.